var documenterSearchIndex = {"docs":
[{"location":"api/#API-reference","page":"API reference","title":"API reference","text":"","category":"section"},{"location":"api/#Index","page":"API reference","title":"Index","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [HiddenMarkovModels]","category":"page"},{"location":"api/#Full-docs","page":"API reference","title":"Full docs","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [HiddenMarkovModels]","category":"page"},{"location":"api/#HiddenMarkovModels.DiscreteMarkovChain","page":"API reference","title":"HiddenMarkovModels.DiscreteMarkovChain","text":"DiscreteMarkovChain\n\nDiscrete-time Markov chain with finite state space.\n\nFields\n\nπ0::AbstractVector: initial state distribution.\nP::AbstractMatrix: state transition matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.DiscreteMarkovChainPrior","page":"API reference","title":"HiddenMarkovModels.DiscreteMarkovChainPrior","text":"DiscreteMarkovChainPrior\n\nDefine a Dirichlet prior on the initial distribution and on the transition matrix of a DiscreteMarkovChain.\n\nFields\n\nπ0_α::AbstractVector: Dirichlet parameter for the initial distribution\nP_α::AbstractMatrix: Dirichlet parameters for the transition matrix\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.DiscreteMarkovChainStats","page":"API reference","title":"HiddenMarkovModels.DiscreteMarkovChainStats","text":"DiscreteMarkovChainStats\n\nStore sufficient statistics for the likelihood of a DiscreteMarkovChain sample.\n\nFields\n\ninitialization_count::AbstractVector: count initializations in each state\ntransition_count::AbstractMatrix: count transitions between each pair of states\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HMM","page":"API reference","title":"HiddenMarkovModels.HMM","text":"HMM\n\nAlias for HiddenMarkovModel.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HMMPrior","page":"API reference","title":"HiddenMarkovModels.HMMPrior","text":"HMMPrior\n\nAlias for HiddenMarkovModelPrior.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HiddenMarkovModel","page":"API reference","title":"HiddenMarkovModels.HiddenMarkovModel","text":"HiddenMarkovModel{Tr,Em}\n\nHidden Markov Model with arbitrary transition model (must be a discrete Markov chain) and emission distributions.\n\nFields\n\ntransitions::Tr: state evolution process.\nemissions::Vector{Em}: one emission distribution per state.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HiddenMarkovModelPrior","page":"API reference","title":"HiddenMarkovModels.HiddenMarkovModelPrior","text":"HiddenMarkovModelPrior{TrP,EmP}\n\nPrior for a HiddenMarkovModel.\n\nFields\n\ntransitions_prior::TrP: prior on the transition structure.\nemissions_prior::Vector{EmP}: one prior per state emission distribution.\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, DiscreteMarkovChain, Integer}","page":"API reference","title":"Base.rand","text":"rand([rng,] mc::DiscreteMarkovChain, T)\n\nSimulate mc during T time steps.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, DiscreteMarkovChainPrior}","page":"API reference","title":"Base.rand","text":"rand([rng,] prior::DiscreteMarkovChainPrior)\n\nSample a DiscreteMarkovChain from prior.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, HiddenMarkovModel, Integer}","page":"API reference","title":"Base.rand","text":"rand([rng,] hmm::HMM, T)\n\nSample a sequence of states of length T and the associated sequence of observations.\n\n\n\n\n\n","category":"method"},{"location":"api/#DensityInterface.logdensityof-Tuple{DiscreteMarkovChain, AbstractVector}","page":"API reference","title":"DensityInterface.logdensityof","text":"logdensityof(mc::DiscreteMarkovChain, x::AbstractVector)\n\nCompute the log-likelihood of the sequence x of states for the chain mc.\n\n\n\n\n\n","category":"method"},{"location":"api/#DensityInterface.logdensityof-Tuple{DiscreteMarkovChainPrior, DiscreteMarkovChain}","page":"API reference","title":"DensityInterface.logdensityof","text":"logdensityof(prior::DiscreteMarkovChainPrior, mc::DiscreteMarkovChain)\n\nCompute the log-likelihood of the chain mc with respect to a prior.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.baum_welch-Tuple{HiddenMarkovModel, AbstractVector}","page":"API reference","title":"HiddenMarkovModels.baum_welch","text":"baum_welch(hmm_init, obs_sequences)\n\nSame as baum_welch_multiple_sequences but with a single sequence.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.baum_welch_multiple_sequences-Tuple{HiddenMarkovModel, AbstractVector}","page":"API reference","title":"HiddenMarkovModels.baum_welch_multiple_sequences","text":"baum_welch_multiple_sequences(hmm_init, obs_sequences)\n\nRun the Baum-Welch algorithm to estimate a HiddenMarkovModel of the same type as hmm_init, based on several observation sequences.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.forward_backward!-Union{Tuple{R}, Tuple{AbstractMatrix{R}, AbstractMatrix{R}, AbstractVector{R}, AbstractMatrix{R}, AbstractArray{R, 3}, HiddenMarkovModel, AbstractMatrix{R}}} where R<:Real","page":"API reference","title":"HiddenMarkovModels.forward_backward!","text":"forward_backward!(α, β, c, γ, ξ, hmm, obs_density)\n\nApply the forward-backward algorithm in-place to update sufficient statistics.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.initial_distribution-Tuple{DiscreteMarkovChain}","page":"API reference","title":"HiddenMarkovModels.initial_distribution","text":"initial_distribution(mc::DiscreteMarkovChain)\n\nReturn the vector of initial state probabilities of mc.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.nb_states-Tuple{DiscreteMarkovChain}","page":"API reference","title":"HiddenMarkovModels.nb_states","text":"nb_states(mc::DiscreteMarkovChain)\n\nReturn the number of states of mc.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.rand_prob_vec-Union{Tuple{R}, Tuple{Type{R}, Integer}} where R<:Real","page":"API reference","title":"HiddenMarkovModels.rand_prob_vec","text":"rand_prob_vec(n)\n\nReturn a random probability distribution vector of size n.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.rand_trans_mat-Union{Tuple{R}, Tuple{Type{R}, Integer}} where R<:Real","page":"API reference","title":"HiddenMarkovModels.rand_trans_mat","text":"rand_trans_mat(n)\n\nReturn a stochastic matrix of size n with random transition probability distributions.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.stationary_distribution-Tuple{DiscreteMarkovChain}","page":"API reference","title":"HiddenMarkovModels.stationary_distribution","text":"stationary_distribution(mc::DiscreteMarkovChain)\n\nCompute the equilibrium distribution of mc using its eigendecomposition.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.transition_matrix-Tuple{DiscreteMarkovChain}","page":"API reference","title":"HiddenMarkovModels.transition_matrix","text":"transition_matrix(mc::DiscreteMarkovChain)\n\nReturn the matrix of transition probabilities of mc.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.uniform_prob_vec-Union{Tuple{R}, Tuple{Type{R}, Integer}} where R<:Real","page":"API reference","title":"HiddenMarkovModels.uniform_prob_vec","text":"uniform_prob_vec(n)\n\nReturn a uniform probability distribution vector of size n.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.uniform_trans_mat-Union{Tuple{R}, Tuple{Type{R}, Integer}} where R<:Real","page":"API reference","title":"HiddenMarkovModels.uniform_trans_mat","text":"uniform_trans_mat(n)\n\nReturn a stochastic matrix of size n with uniform transition probability distributions.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.update_obs_density!-Union{Tuple{R}, Tuple{AbstractMatrix{R}, HiddenMarkovModel, AbstractVector}} where R<:Real","page":"API reference","title":"HiddenMarkovModels.update_obs_density!","text":"update_obs_density!(obs_density, hmm, obs_sequence)\n\nSet obs_density[s, t] to the likelihood of hmm emitting obs_sequence[t] if it were in state s.\n\n\n\n\n\n","category":"method"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"EditURL = \"https://github.com/gdalle/HiddenMarkovModels.jl/blob/main/test/discrete_markov.jl\"","category":"page"},{"location":"examples/discrete_markov/#Discrete-Markov-chain","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"","category":"section"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"using HiddenMarkovModels\nusing LogarithmicNumbers\nusing Statistics\nusing UnicodePlots","category":"page"},{"location":"examples/discrete_markov/#Construction","page":"Discrete Markov chain","title":"Construction","text":"","category":"section"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"A DiscreteMarkovChain object is built by combining a vector of initial probabilities with a transition matrix.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"π0 = [0.3, 0.7]\nP = [0.9 0.1; 0.2 0.8]\nmc = DiscreteMarkovChain(π0, P)","category":"page"},{"location":"examples/discrete_markov/#Simulation","page":"Discrete Markov chain","title":"Simulation","text":"","category":"section"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"To simulate it, we only need to decide how long the sequence should be.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"state_sequence = rand(mc, 100);\nscatterplot(\n    state_sequence;\n    label=nothing,\n    title=\"Markov chain evolution\",\n    xlabel=\"Time\",\n    ylabel=\"State\",\n)","category":"page"},{"location":"examples/discrete_markov/#Learning","page":"Discrete Markov chain","title":"Learning","text":"","category":"section"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"Based on a sequence of states, we can fit a DiscreteMarkovChain with Maximum Likelihood Estimation (MLE). To speed up estimation, we can specify the types of the parameters to estimate, for instance Float32 instead of Float64.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"mc_mle = fit_mle(DiscreteMarkovChain{Float32,Float32}, state_sequence)","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"As we can see, the error on the transition matrix is quite small.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"error_mle = mean(abs, transition_matrix(mc_mle) - transition_matrix(mc))","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"We can also use a Maximum A Posteriori (MAP) approach by specifying a conjugate prior, which contains observed pseudocounts of intializations and transitions. Let's say we have previously observed 4 trajectories of length 10, with balanced initializations and transitions.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"π0_α = 1 .+ 4 * [0.5, 0.5]\nP_α = 1 .+ 4 * 10 * [0.5 0.5; 0.5 0.5]\nmc_prior = DiscreteMarkovChainPrior(π0_α, P_α)\n\nmc_map = fit_map(DiscreteMarkovChain{Float32,Float32}, mc_prior, state_sequence)","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"This results in an estimate that puts larger weights on transitions between states 1 and 2","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"transition_matrix(mc_map) - transition_matrix(mc_mle)","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"Finally, if we fear very small transition probabilities, we can perform the entire estimation in log scale thanks to LogarithmicNumbers.jl.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"mc_mle_log = fit_mle(DiscreteMarkovChain{LogFloat32,LogFloat32}, state_sequence)\n\nerror_mle_log = mean(abs, transition_matrix(mc_mle_log) - transition_matrix(mc))","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"This page was generated using Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = HiddenMarkovModels","category":"page"},{"location":"#HiddenMarkovModels.jl","page":"Home","title":"HiddenMarkovModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Welcome to the documentation of HiddenMarkovModels.jl, a lightweight package for working with Markov chains and Hidden Markov Models.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the package, open a Julia Pkg REPL and run","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/gdalle/HiddenMarkovModels.jl","category":"page"},{"location":"#Mathematical-background","page":"Home","title":"Mathematical background","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To understand the algorithms implemented here, check out the following literature:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition, Lawrence R. Rabiner (1989)","category":"page"},{"location":"#Alternatives","page":"Home","title":"Alternatives","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you don't find what you are looking for around here, there are several other Julia packages with a focus on Markovian modeling. Here are the ones that I am aware of:","category":"page"},{"location":"","page":"Home","title":"Home","text":"HMMBase.jl\nMarkovModels.jl\nHiddenMarkovModels.jl\nMitosis.jl\nContinuousTimeMarkov.jl\nPiecewiseDeterministicMarkovProcesses.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"The reason I implemented my own was because I needed specific features that were not simultaneously available elsewhere (to the best of my knowledge):","category":"page"},{"location":"","page":"Home","title":"Home","text":"Compatibility with generic emissions that go beyond Distributions.jl objects\nNumerical stability thanks to log-scale computations\nDiscrete and continuous time versions (WIP)\nMAP estimation with priors (WIP)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"EditURL = \"https://github.com/gdalle/HiddenMarkovModels.jl/blob/main/test/hmm.jl\"","category":"page"},{"location":"examples/hmm/#Hidden-Markov-Model","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"using Distributions\nusing HiddenMarkovModels\nusing LogarithmicNumbers\nusing Statistics","category":"page"},{"location":"examples/hmm/#Construction","page":"Hidden Markov Model","title":"Construction","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"A HiddenMarkovModel object is build by combining a transition structure (of type DiscreteMarkovChain) with a list of emission distributions.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"π0 = [0.3, 0.7]\nP = [0.9 0.1; 0.2 0.8]\ntransitions = DiscreteMarkovChain(π0, P)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"emission1 = Normal(0.4, 0.7)\nemission2 = Normal(-0.8, 0.3)\nemissions = [emission1, emission2]","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm = HiddenMarkovModel(transitions, emissions)","category":"page"},{"location":"examples/hmm/#Simulation","page":"Hidden Markov Model","title":"Simulation","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"The simulation utility returns both the sequence of states and the sequence of observations.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"state_sequence, obs_sequence = rand(hmm, 10)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"With the learning step in mind, we want to generate multiple observations sequences of various lengths.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"obs_sequences = [rand(hmm, rand(200:1000))[2] for k in 1:5];\nnothing #hide","category":"page"},{"location":"examples/hmm/#Learning","page":"Hidden Markov Model","title":"Learning","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"The Baum-Welch algorithm for estimating HMM parameters requires an initial guess, which we choose arbitrarily. Initial parameters can be created with reduced precision to speed up estimation.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm_init = HiddenMarkovModel(\n    DiscreteMarkovChain(rand_prob_vec(Float32, 2), rand_trans_mat(Float32, 2)),\n    [Normal(one(Float32)), Normal(-one(Float32))],\n)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"We can now apply the algorithm by setting a tolerance on the loglikelihood increase, as well as a maximum number of iterations.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm_est, logL_evolution = baum_welch_multiple_sequences(\n    hmm_init, obs_sequences; max_iterations=1000, tol=1e-5, plot=true\n);\nnothing #hide","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"As we can see on the plot, each iteration increases the loglikelihood of the estimate: it is a fundamental property of the EM algorithm and its variants.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"To improve numerical stability, we can apply the algorithm directly in log scale thanks to LogarithmicNumbers.jl.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm_init_log = HiddenMarkovModel(\n    DiscreteMarkovChain(rand_prob_vec(LogFloat64, 2), rand_trans_mat(LogFloat64, 2)),\n    [Normal(one(LogFloat64)), Normal(-one(LogFloat64))],\n)\n\nhmm_est_log, logL_evolution_log = baum_welch_multiple_sequences(\n    hmm_init_log, obs_sequences; max_iterations=1000, tol=1e-5, plot=true\n);\nnothing #hide","category":"page"},{"location":"examples/hmm/#Checking-results","page":"Hidden Markov Model","title":"Checking results","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"Let us now compute the estimation error on various parameters.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"transition_error_init = mean(abs, transition_matrix(hmm_init) - transition_matrix(hmm))\nμ_error_init = mean(abs, [emission(hmm_init, s).μ - emission(hmm, s).μ for s in 1:2])\nσ_error_init = mean(abs, [emission(hmm_init, s).σ - emission(hmm, s).σ for s in 1:2])\n(transition_error_init, μ_error_init, σ_error_init)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"transition_error = mean(abs, transition_matrix(hmm_est) - transition_matrix(hmm))\nμ_error = mean(abs, [emission(hmm_est, s).μ - emission(hmm, s).μ for s in 1:2])\nσ_error = mean(abs, [emission(hmm_est, s).σ - emission(hmm, s).σ for s in 1:2])\n(transition_error, μ_error, σ_error)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"As we can see, all of these errors are much smaller than those of hmm_init: mission accomplished! The same goes for the logarithmic version.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"transition_error_init_log = mean(\n    float ∘ abs, transition_matrix(hmm_init_log) - transition_matrix(hmm)\n)\nμ_error_init_log = mean(\n    float ∘ abs, [emission(hmm_init_log, s).μ - emission(hmm, s).μ for s in 1:2]\n)\nσ_error_init_log = mean(\n    float ∘ abs, [emission(hmm_init_log, s).σ - emission(hmm, s).σ for s in 1:2]\n)\n\n(transition_error_init_log, μ_error_init_log, σ_error_init_log)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"transition_error_log = mean(\n    float ∘ abs, transition_matrix(hmm_est_log) - transition_matrix(hmm)\n)\nμ_error_log = mean(\n    float ∘ abs, [emission(hmm_est_log, s).μ - emission(hmm, s).μ for s in 1:2]\n)\nσ_error_log = mean(\n    float ∘ abs, [emission(hmm_est_log, s).σ - emission(hmm, s).σ for s in 1:2]\n)\n\n(transition_error_log, μ_error_log, σ_error_log)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"This page was generated using Literate.jl.","category":"page"}]
}
