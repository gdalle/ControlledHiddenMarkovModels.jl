var documenterSearchIndex = {"docs":
[{"location":"api/#API-reference","page":"API reference","title":"API reference","text":"","category":"section"},{"location":"api/#Index","page":"API reference","title":"Index","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [HiddenMarkovModels]","category":"page"},{"location":"api/#Full-docs","page":"API reference","title":"Full docs","text":"","category":"section"},{"location":"api/","page":"API reference","title":"API reference","text":"Modules = [HiddenMarkovModels]","category":"page"},{"location":"api/#HiddenMarkovModels.DiscreteMarkovChain","page":"API reference","title":"HiddenMarkovModels.DiscreteMarkovChain","text":"DiscreteMarkovChain\n\nDiscrete-time Markov chain with finite state space.\n\nFields\n\nπ0::AbstractVector: initial state distribution.\nP::AbstractMatrix: state transition matrix.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.DiscreteMarkovChainPrior","page":"API reference","title":"HiddenMarkovModels.DiscreteMarkovChainPrior","text":"DiscreteMarkovChainPrior\n\nDefine a Dirichlet prior on the initial distribution and on the transition matrix of a DiscreteMarkovChain.\n\nFields\n\nπ0_α::AbstractVector: Dirichlet parameter for the initial distribution\nP_α::AbstractMatrix: Dirichlet parameters for the transition matrix\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.DiscreteMarkovChainStats","page":"API reference","title":"HiddenMarkovModels.DiscreteMarkovChainStats","text":"DiscreteMarkovChainStats\n\nStore sufficient statistics for the likelihood of a DiscreteMarkovChain sample.\n\nFields\n\ninitialization_count::AbstractVector: count initializations in each state\ntransition_count::AbstractMatrix: count transitions between each pair of states\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HMM","page":"API reference","title":"HiddenMarkovModels.HMM","text":"HMM\n\nAlias for HiddenMarkovModel.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HMMPrior","page":"API reference","title":"HiddenMarkovModels.HMMPrior","text":"HMMPrior\n\nAlias for HiddenMarkovModelPrior.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HiddenMarkovModel","page":"API reference","title":"HiddenMarkovModels.HiddenMarkovModel","text":"HiddenMarkovModel{T,E}\n\nHidden Markov Model with arbitrary transition model (must be a discrete Markov chain) and emission distributions.\n\nFields\n\ntransitions::T: state evolution process.\nemissions::Vector{E}: one emission distribution per state.\n\n\n\n\n\n","category":"type"},{"location":"api/#HiddenMarkovModels.HiddenMarkovModelPrior","page":"API reference","title":"HiddenMarkovModels.HiddenMarkovModelPrior","text":"HiddenMarkovModelPrior{TP,EP}\n\nPrior for a HiddenMarkovModel.\n\nFields\n\ntransitions_prior::T: prior on the transition structure.\nemissions_prior::Vector{E}: one prior per state emission distribution.\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, DiscreteMarkovChain, Integer}","page":"API reference","title":"Base.rand","text":"rand([rng,] mc::DiscreteMarkovChain, T)\n\nSimulate mc during T time steps.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, DiscreteMarkovChainPrior}","page":"API reference","title":"Base.rand","text":"rand([rng,] prior::DiscreteMarkovChainPrior)\n\nSample a DiscreteMarkovChain from prior.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, HiddenMarkovModel, Integer}","page":"API reference","title":"Base.rand","text":"rand([rng,] hmm::HMM, T)\n\nSample a sequence of states of length T and the associated sequence of observations.\n\n\n\n\n\n","category":"method"},{"location":"api/#DensityInterface.logdensityof-Tuple{DiscreteMarkovChain, AbstractVector}","page":"API reference","title":"DensityInterface.logdensityof","text":"logdensityof(mc::DiscreteMarkovChain, x::AbstractVector)\n\nCompute the log-likelihood of the sequence x of states for the chain mc.\n\n\n\n\n\n","category":"method"},{"location":"api/#DensityInterface.logdensityof-Tuple{DiscreteMarkovChainPrior, DiscreteMarkovChain}","page":"API reference","title":"DensityInterface.logdensityof","text":"logdensityof(prior::DiscreteMarkovChainPrior, mc::DiscreteMarkovChain)\n\nCompute the log-likelihood of the chain mc with respect to a prior.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.baum_welch-Tuple{Any, Any}","page":"API reference","title":"HiddenMarkovModels.baum_welch","text":"baum_welch(hmm_init, observation_sequence; log, plot)\n\nRun the Baum-Welch algorithm to estimate a HiddenMarkovModel of the same type as hmm_init, based on a single observation_sequence.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.baum_welch_multiple_sequences-Union{Tuple{Em}, Tuple{Tr}, Tuple{HiddenMarkovModel{Tr, Em}, Any}} where {Tr, Em}","page":"API reference","title":"HiddenMarkovModels.baum_welch_multiple_sequences","text":"baum_welch_multiple_sequences(hmm_init, observation_sequences; iterations)\n\nRun the Baum-Welch algorithm to estimate a HiddenMarkovModel of the same type as hmm_init, based on several observation_sequences.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.baum_welch_multiple_sequences_log-Union{Tuple{Em}, Tuple{Tr}, Tuple{HiddenMarkovModel{Tr, Em}, Any}} where {Tr, Em}","page":"API reference","title":"HiddenMarkovModels.baum_welch_multiple_sequences_log","text":"baum_welch_multiple_sequences_log(hmm_init, observation_sequences; iterations)\n\nSame as baum_welch_multiple_sequences but with logarithmic computations for numerical stability.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.forward_backward!-Tuple{AbstractMatrix, AbstractMatrix, AbstractVector, AbstractMatrix, AbstractArray{<:Real, 3}, AbstractMatrix, HiddenMarkovModel}","page":"API reference","title":"HiddenMarkovModels.forward_backward!","text":"forward_backward!(α, β, c, γ, ξ, obs_density, hmm)\n\nApply the forward-backward algorithm in-place to compute sufficient statistics.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.forward_backward_log!-Tuple{AbstractMatrix, AbstractMatrix, AbstractMatrix, AbstractArray{<:Real, 3}, AbstractMatrix, HiddenMarkovModel}","page":"API reference","title":"HiddenMarkovModels.forward_backward_log!","text":"forward_backward!(logα, logβ, logγ, logξ, obs_logdensity, hmm)\n\nApply the logarithmic forward-backward algorithm in-place to compute sufficient statistics.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.initial_distribution-Tuple{DiscreteMarkovChain}","page":"API reference","title":"HiddenMarkovModels.initial_distribution","text":"initial_distribution(mc::DiscreteMarkovChain)\n\nReturn the vector of initial state probabilities of mc.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.nb_states-Tuple{DiscreteMarkovChain}","page":"API reference","title":"HiddenMarkovModels.nb_states","text":"nb_states(mc::DiscreteMarkovChain)\n\nReturn the number of states of mc.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.randprobvec-Tuple{Any}","page":"API reference","title":"HiddenMarkovModels.randprobvec","text":"randprobvec(n)\n\nReturn a random probability distribution vector of size n.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.randtransmat-Tuple{Any}","page":"API reference","title":"HiddenMarkovModels.randtransmat","text":"randtransmat(n)\n\nReturn a stochastic matrix of size n with random transition probability distributions.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.stationary_distribution-Tuple{DiscreteMarkovChain}","page":"API reference","title":"HiddenMarkovModels.stationary_distribution","text":"stationary_distribution(mc::DiscreteMarkovChain)\n\nCompute the equilibrium distribution of mc using its eigendecomposition.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.transition_matrix-Tuple{DiscreteMarkovChain}","page":"API reference","title":"HiddenMarkovModels.transition_matrix","text":"transition_matrix(mc::DiscreteMarkovChain)\n\nReturn the matrix of transition probabilities of mc.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.uniformprobvec-Tuple{Any}","page":"API reference","title":"HiddenMarkovModels.uniformprobvec","text":"uniformprobvec(n)\n\nReturn a uniform probability distribution vector of size n.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.uniformtransmat-Tuple{Any}","page":"API reference","title":"HiddenMarkovModels.uniformtransmat","text":"uniformtransmat(n)\n\nReturn a stochastic matrix of size n with uniform transition probability distributions.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.update_obs_density!-Tuple{AbstractMatrix, AbstractVector, HiddenMarkovModel}","page":"API reference","title":"HiddenMarkovModels.update_obs_density!","text":"update_obs_density!(obs_density, observations, hmm)\n\nSet obs_density[t, s] to the likelihood of hmm emitting observation[t] if it were in state s.\n\n\n\n\n\n","category":"method"},{"location":"api/#HiddenMarkovModels.update_obs_logdensity!-Tuple{AbstractMatrix, AbstractVector, HiddenMarkovModel}","page":"API reference","title":"HiddenMarkovModels.update_obs_logdensity!","text":"update_obs_logdensity!(obs_density, observations, hmm)\n\nSet obs_logdensity[t, s] to the log-likelihood of hmm emitting observation[t] if it were in state s.\n\n\n\n\n\n","category":"method"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"EditURL = \"https://github.com/gdalle/HiddenMarkovModels.jl/blob/main/test/discrete_markov.jl\"","category":"page"},{"location":"examples/discrete_markov/#Discrete-Markov-chain","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"","category":"section"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"using HiddenMarkovModels\nusing Plots\nusing Statistics","category":"page"},{"location":"examples/discrete_markov/#Construction","page":"Discrete Markov chain","title":"Construction","text":"","category":"section"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"A DiscreteMarkovChain object is built by combining a vector of initial probabilities with a transition matrix.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"π0 = [0.3, 0.7]\nP = [0.9 0.1; 0.2 0.8]\ndmc = DiscreteMarkovChain(π0, P)","category":"page"},{"location":"examples/discrete_markov/#Simulation","page":"Discrete Markov chain","title":"Simulation","text":"","category":"section"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"To simulate it, we only need to decide how long the sequence should be.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"states = rand(dmc, 100);\nscatter(states, label=nothing, xlabel=\"Time\", ylabel=\"Markov chain state\")","category":"page"},{"location":"examples/discrete_markov/#Learning","page":"Discrete Markov chain","title":"Learning","text":"","category":"section"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"Based on a sequence of states, we can fit a DiscreteMarkovChain with Maximum Likelihood.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"dmc_est_mle = fit_mle(DiscreteMarkovChain, states)","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"As we can see, the error on the transition matrix is quite small.","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"error_mle = mean(abs, transition_matrix(dmc_est_mle) - transition_matrix(dmc))","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"","category":"page"},{"location":"examples/discrete_markov/","page":"Discrete Markov chain","title":"Discrete Markov chain","text":"This page was generated using Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = HiddenMarkovModels","category":"page"},{"location":"#HiddenMarkovModels.jl","page":"Home","title":"HiddenMarkovModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Welcome to the documentation of HiddenMarkovModels.jl, a lightweight package for working with Markov chains and Hidden Markov Models.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the package, open a Julia Pkg REPL and run","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/gdalle/HiddenMarkovModels.jl","category":"page"},{"location":"#Mathematical-background","page":"Home","title":"Mathematical background","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To understand the algorithms implemented here, check out the following literature:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition, Lawrence R. Rabiner (1989)","category":"page"},{"location":"#Alternatives","page":"Home","title":"Alternatives","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you don't find what you are looking for around here, there are several other Julia packages with a focus on Markovian modeling. Here are the ones that I am aware of:","category":"page"},{"location":"","page":"Home","title":"Home","text":"HMMBase.jl\nMarkovModels.jl\nMitosis.jl\nContinuousTimeMarkov.jl\nPiecewiseDeterministicMarkovProcesses.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"The reason I implemented my own was because I needed specific features that were not simultaneously available elsewhere (to the best of my knowledge):","category":"page"},{"location":"","page":"Home","title":"Home","text":"Compatibility with generic emissions that go beyond Distributions.jl objects\nDiscrete and continuous time versions\nMAP estimation with priors","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"EditURL = \"https://github.com/gdalle/HiddenMarkovModels.jl/blob/main/test/hmm.jl\"","category":"page"},{"location":"examples/hmm/#Hidden-Markov-Model","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"using Distributions\nusing HiddenMarkovModels\nusing Plots\nusing Statistics","category":"page"},{"location":"examples/hmm/#Construction","page":"Hidden Markov Model","title":"Construction","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"A HiddenMarkovModel object is build by combining a transition structure (typically a DiscreteMarkovChain) with a list of emission distributions.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"π0 = [0.3, 0.7]\nP = [0.9 0.1; 0.2 0.8]\ntransitions = DiscreteMarkovChain(π0, P)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"emission1 = Normal(0.4, 0.7)\nemission2 = Normal(-0.8, 0.3)\nemissions = [emission1, emission2]","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm = HiddenMarkovModel(transitions, emissions)","category":"page"},{"location":"examples/hmm/#Simulation","page":"Hidden Markov Model","title":"Simulation","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"The simulation utility returns both the sequence of states and the sequence of observations.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"states, observations = rand(hmm, 10)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"With the learning step in mind, we want to generate multiple observations sequences of various lengths.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"observation_sequences = [rand(hmm, rand(300:500))[2] for k in 1:5];\nnothing #hide","category":"page"},{"location":"examples/hmm/#Learning","page":"Hidden Markov Model","title":"Learning","text":"","category":"section"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"The Baum-Welch algorithm for estimating HMM parameters requires an initial guess, which we choose arbitrarily.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"transitions_init = DiscreteMarkovChain(; π0=randprobvec(2), P=randtransmat(2))\nemissions_init = [Normal(1, 1), Normal(-1, 1)]\nhmm_init = HiddenMarkovModel(transitions_init, emissions_init)","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"We can either use the standard version with a scaling trick...","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm_est1, logL_evolution1 = baum_welch_multiple_sequences(\n    hmm_init, observation_sequences; iterations=20\n);\nplot(logL_evolution1, label=nothing, xlabel=\"Baum-Welch iteration\", ylabel=\"Loglikelihood\")","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm_est1","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"... or the logarithmic version (which is more robust but much slower).","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm_est2, logL_evolution2 = baum_welch_multiple_sequences_log(\n    hmm_init, observation_sequences; iterations=20\n);\nplot(logL_evolution2, label=nothing, xlabel=\"Baum-Welch iteration\", ylabel=\"Loglikelihood\")","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"hmm_est2","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"As we can see on the plots, both procedures increase the loglikelihood of the estimate, as they should.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"Let us now compute the estimation error on various parameters.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"transition_error1 = mean(abs, transition_matrix(hmm_est1) - transition_matrix(hmm))\ntransition_error2 = mean(abs, transition_matrix(hmm_est2) - transition_matrix(hmm))\ntransition_error1, transition_error2","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"μ_error1 = mean(abs, [emission(hmm_est1, s).μ - emission(hmm, s).μ for s in 1:2])\nμ_error2 = mean(abs, [emission(hmm_est2, s).μ - emission(hmm, s).μ for s in 1:2])\nμ_error1, μ_error2","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"σ_error1 = mean(abs, [emission(hmm_est1, s).σ - emission(hmm, s).σ for s in 1:2])\nσ_error2 = mean(abs, [emission(hmm_est2, s).σ - emission(hmm, s).σ for s in 1:2])\nσ_error1, σ_error2","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"Since both estimators perform the same operations but on a different scale (standard vs. logarithmic), it is not surprising that their errors coincide up to numerical precision.","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"More importantly, all of these errors are much smaller than those of hmm_init: mission accomplished!","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"","category":"page"},{"location":"examples/hmm/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"This page was generated using Literate.jl.","category":"page"}]
}
