<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Hidden Markov Model · HiddenMarkovModels.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://gdalle.github.io/HiddenMarkovModels.jl/examples/hmm/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">HiddenMarkovModels.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../discrete_markov/">Discrete Markov chain</a></li><li class="is-active"><a class="tocitem" href>Hidden Markov Model</a><ul class="internal"><li><a class="tocitem" href="#Construction"><span>Construction</span></a></li><li><a class="tocitem" href="#Simulation"><span>Simulation</span></a></li><li><a class="tocitem" href="#Learning"><span>Learning</span></a></li><li><a class="tocitem" href="#Checking-results"><span>Checking results</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../api/">API reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Hidden Markov Model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Hidden Markov Model</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/gdalle/HiddenMarkovModels.jl/blob/main/test/hmm.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Hidden-Markov-Model"><a class="docs-heading-anchor" href="#Hidden-Markov-Model">Hidden Markov Model</a><a id="Hidden-Markov-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Hidden-Markov-Model" title="Permalink"></a></h1><pre><code class="language-julia hljs">using Distributions
using HiddenMarkovModels
using LogarithmicNumbers
using Statistics</code></pre><h2 id="Construction"><a class="docs-heading-anchor" href="#Construction">Construction</a><a id="Construction-1"></a><a class="docs-heading-anchor-permalink" href="#Construction" title="Permalink"></a></h2><p>A <a href="../../api/#HiddenMarkovModels.HiddenMarkovModel"><code>HiddenMarkovModel</code></a> object is build by combining a transition structure (of type <a href="../../api/#HiddenMarkovModels.DiscreteMarkovChain"><code>DiscreteMarkovChain</code></a>) with a list of emission distributions.</p><pre><code class="language-julia hljs">π0 = [0.3, 0.7]
P = [0.9 0.1; 0.2 0.8]
transitions = DiscreteMarkovChain(π0, P)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DiscreteMarkovChain{Float64, Float64}([0.3, 0.7], [0.9 0.1; 0.2 0.8])</code></pre><pre><code class="language-julia hljs">emission1 = Normal(0.4, 0.7)
emission2 = Normal(-0.8, 0.3)
emissions = [emission1, emission2]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Distributions.Normal{Float64}}:
 Distributions.Normal{Float64}(μ=0.4, σ=0.7)
 Distributions.Normal{Float64}(μ=-0.8, σ=0.3)</code></pre><pre><code class="language-julia hljs">hmm = HiddenMarkovModel(transitions, emissions)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">HiddenMarkovModel{DiscreteMarkovChain{Float64, Float64}, Distributions.Normal{Float64}}(DiscreteMarkovChain{Float64, Float64}([0.3, 0.7], [0.9 0.1; 0.2 0.8]), Distributions.Normal{Float64}[Distributions.Normal{Float64}(μ=0.4, σ=0.7), Distributions.Normal{Float64}(μ=-0.8, σ=0.3)])</code></pre><h2 id="Simulation"><a class="docs-heading-anchor" href="#Simulation">Simulation</a><a id="Simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Simulation" title="Permalink"></a></h2><p>The simulation utility returns both the sequence of states and the sequence of observations.</p><pre><code class="language-julia hljs">state_sequence, obs_sequence = rand(hmm, 10)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([2, 2, 2, 2, 2, 1, 1, 2, 2, 1], [-1.0667171425411728, -0.7805081066703982, -0.8439658024413738, -0.6884752674388587, -0.913146967155405, -0.40422101110878905, 0.5266173603201603, -0.8821113744083494, -0.6602269098058472, 0.6702981511792152])</code></pre><p>With the learning step in mind, we want to generate multiple observations sequences of various lengths.</p><pre><code class="language-julia hljs">obs_sequences = [rand(hmm, rand(200:1000))[2] for k in 1:5];</code></pre><h2 id="Learning"><a class="docs-heading-anchor" href="#Learning">Learning</a><a id="Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Learning" title="Permalink"></a></h2><p>The Baum-Welch algorithm for estimating HMM parameters requires an initial guess, which we choose arbitrarily. Initial parameters can be created with reduced precision to speed up estimation.</p><pre><code class="language-julia hljs">hmm_init = HiddenMarkovModel(
    DiscreteMarkovChain(rand_prob_vec(Float32, 2), rand_trans_mat(Float32, 2)),
    [Normal(one(Float32)), Normal(-one(Float32))],
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">HiddenMarkovModel{DiscreteMarkovChain{Float32, Float32}, Distributions.Normal{Float32}}(DiscreteMarkovChain{Float32, Float32}(Float32[0.7315456, 0.2684544], Float32[0.7260029 0.27399716; 0.64613616 0.35386384]), Distributions.Normal{Float32}[Distributions.Normal{Float32}(μ=1.0f0, σ=1.0f0), Distributions.Normal{Float32}(μ=-1.0f0, σ=1.0f0)])</code></pre><p>We can now apply the algorithm by setting a tolerance on the loglikelihood increase, as well as a maximum number of iterations.</p><pre><code class="language-julia hljs">hmm_est, logL_evolution = baum_welch_multiple_sequences(
    hmm_init, obs_sequences; max_iterations=1000, tol=1e-5, plot=true
);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">                        ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Baum-Welch convergence⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
                        ┌────────────────────────────────────────┐
                  -3000 │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⢀⠤⠒⠒⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠁⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⡠⠊⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⢰⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
   Log-likelihood       │⠀⠀⠀⡸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⢰⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⡸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                  -6000 │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        └────────────────────────────────────────┘
                        ⠀0⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀20⠀
                        ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Iteration⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀</code></pre><p>As we can see on the plot, each iteration increases the loglikelihood of the estimate: it is a fundamental property of the EM algorithm and its variants.</p><p>To improve numerical stability, we can apply the algorithm directly in log scale thanks to <a href="https://github.com/cjdoris/LogarithmicNumbers.jl">LogarithmicNumbers.jl</a>.</p><pre><code class="language-julia hljs">hmm_init_log = HiddenMarkovModel(
    DiscreteMarkovChain(rand_prob_vec(LogFloat64, 2), rand_trans_mat(LogFloat64, 2)),
    [Normal(one(LogFloat64)), Normal(-one(LogFloat64))],
)

hmm_est_log, logL_evolution_log = baum_welch_multiple_sequences(
    hmm_init_log, obs_sequences; max_iterations=1000, tol=1e-5, plot=true
);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">                        ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Baum-Welch convergence⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
                        ┌────────────────────────────────────────┐
                  -3000 │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⢀⡠⠤⠒⠒⠊⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⢀⡠⠊⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⢰⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
   Log-likelihood       │⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⢸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                  -6000 │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│
                        └────────────────────────────────────────┘
                        ⠀0⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀30⠀
                        ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Iteration⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀</code></pre><h2 id="Checking-results"><a class="docs-heading-anchor" href="#Checking-results">Checking results</a><a id="Checking-results-1"></a><a class="docs-heading-anchor-permalink" href="#Checking-results" title="Permalink"></a></h2><p>Let us now compute the estimation error on various parameters.</p><pre><code class="language-julia hljs">transition_error_init = mean(abs, transition_matrix(hmm_init) - transition_matrix(hmm))
μ_error_init = mean(abs, [emission(hmm_init, s).μ - emission(hmm, s).μ for s in 1:2])
σ_error_init = mean(abs, [emission(hmm_init, s).σ - emission(hmm, s).σ for s in 1:2])
(transition_error_init, μ_error_init, σ_error_init)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(0.31006665378808973, 0.39999999999999997, 0.5)</code></pre><pre><code class="language-julia hljs">transition_error = mean(abs, transition_matrix(hmm_est) - transition_matrix(hmm))
μ_error = mean(abs, [emission(hmm_est, s).μ - emission(hmm, s).μ for s in 1:2])
σ_error = mean(abs, [emission(hmm_est, s).σ - emission(hmm, s).σ for s in 1:2])
(transition_error, μ_error, σ_error)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(0.003653313592076289, 0.024289515614509594, 0.010951209068298356)</code></pre><p>As we can see, all of these errors are much smaller than those of <code>hmm_init</code>: mission accomplished! The same goes for the logarithmic version.</p><pre><code class="language-julia hljs">transition_error_init_log = mean(
    float ∘ abs, transition_matrix(hmm_init_log) - transition_matrix(hmm)
)
μ_error_init_log = mean(
    float ∘ abs, [emission(hmm_init_log, s).μ - emission(hmm, s).μ for s in 1:2]
)
σ_error_init_log = mean(
    float ∘ abs, [emission(hmm_init_log, s).σ - emission(hmm, s).σ for s in 1:2]
)

(transition_error_init_log, μ_error_init_log, σ_error_init_log)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(0.30059520856559074, 0.39999999999999997, 0.5)</code></pre><pre><code class="language-julia hljs">transition_error_log = mean(
    float ∘ abs, transition_matrix(hmm_est_log) - transition_matrix(hmm)
)
μ_error_log = mean(
    float ∘ abs, [emission(hmm_est_log, s).μ - emission(hmm, s).μ for s in 1:2]
)
σ_error_log = mean(
    float ∘ abs, [emission(hmm_est_log, s).σ - emission(hmm, s).σ for s in 1:2]
)

(transition_error_log, μ_error_log, σ_error_log)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(0.0038546961991583104, 0.02408509752268448, 0.011089710781284082)</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../discrete_markov/">« Discrete Markov chain</a><a class="docs-footer-nextpage" href="../../api/">API reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.16 on <span class="colophon-date" title="Sunday 8 May 2022 10:40">Sunday 8 May 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
